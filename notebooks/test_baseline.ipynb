{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ef190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 22:58:31,205 - INFO - Loading data...\n",
      "2026-01-14 22:58:31,214 - INFO - Loaded config.json\n",
      "2026-01-14 22:58:31,214 - INFO - Loaded config.json\n",
      "2026-01-14 22:58:31,225 - INFO - Loaded stp_registry.csv (4 records)\n",
      "2026-01-14 22:58:31,225 - INFO - Loaded stp_registry.csv (4 records)\n",
      "2026-01-14 22:58:31,230 - INFO - Loaded farm_locations.csv (20 records)\n",
      "2026-01-14 22:58:31,230 - INFO - Loaded farm_locations.csv (20 records)\n",
      "2026-01-14 22:58:31,241 - INFO - Loaded 4 STPs and 20 farms\n",
      "2026-01-14 22:58:31,302 - INFO - Loaded demand data: 91250 records\n",
      "2026-01-14 22:58:31,303 - INFO - Loaded weather data: 1825 records\n",
      "2026-01-14 22:58:31,304 - INFO - Initializing algorithm...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\Prasanna rajan R\\Documents\\GitHub\\kerala-biosolids-hackathon\\notebooks\n",
      "Current directory: c:\\Users\\Prasanna rajan R\\Documents\\GitHub\\kerala-biosolids-hackathon\\notebooks\n",
      "WARNING: 'data' folder not found in current directory\n",
      "Switching to parent directory...\n",
      "New working directory: c:\\Users\\Prasanna rajan R\\Documents\\GitHub\\kerala-biosolids-hackathon\n",
      "Project root added to sys.path: c:\\Users\\Prasanna rajan R\\Documents\\GitHub\\kerala-biosolids-hackathon\n",
      "Python path: ['C:\\\\Users\\\\Prasanna rajan R\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python311.zip', 'C:\\\\Users\\\\Prasanna rajan R\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\DLLs', 'C:\\\\Users\\\\Prasanna rajan R\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib', 'C:\\\\Users\\\\Prasanna rajan R\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311', 'c:\\\\Users\\\\Prasanna rajan R\\\\Documents\\\\GitHub\\\\kerala-biosolids-hackathon\\\\.venv', '', 'c:\\\\Users\\\\Prasanna rajan R\\\\Documents\\\\GitHub\\\\kerala-biosolids-hackathon\\\\.venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\Prasanna rajan R\\\\Documents\\\\GitHub\\\\kerala-biosolids-hackathon', 'c:\\\\Users\\\\Prasanna rajan R\\\\Documents\\\\GitHub\\\\kerala-biosolids-hackathon\\\\src']\n",
      "\n",
      "======================================================================\n",
      "STEP 8: COMPREHENSIVE ALGORITHM TEST\n",
      "======================================================================\n",
      "Data directory: c:\\Users\\Prasanna rajan R\\Documents\\GitHub\\kerala-biosolids-hackathon\\data\n",
      "\n",
      "1ï¸âƒ£ SETUP\n",
      "----------------------------------------\n",
      "\n",
      "Checking data files...\n",
      "âœ“ Found: parameters.json\n",
      "âœ“ Found: stp_registry.csv\n",
      "âœ“ Found: farm_locations.csv\n",
      "âœ“ Found: daily_n_demand.csv\n",
      "âœ“ Found: weather_forecast.csv\n",
      "======================================================================\n",
      "                        DATA VALIDATION REPORT                        \n",
      "======================================================================\n",
      "\n",
      "GLOBAL PARAMETERS\n",
      "----------------------------------------------------------------------\n",
      "simulation_metadata           : {'year': 2025, 'region': 'Kerala', 'currency': 'Carbon Credits (kg CO2 eq)'}\n",
      "logistics_constants           : {'truck_capacity_tons': 10, 'diesel_emission_factor_kg_co2_per_km': 0.9, 'haversine_earth_radius_km': 6371}\n",
      "agronomic_constants           : {'nitrogen_content_kg_per_ton_biosolid': 25, 'synthetic_n_offset_credit_kg_co2_per_kg_n': 5.0, 'soil_organic_carbon_gain_kg_co2_per_kg_biosolid': 0.2, 'leaching_penalty_kg_co2_per_kg_excess_n': 10.0, 'application_buffer_percent': 10}\n",
      "environmental_thresholds      : {'rain_lock_threshold_mm': 30.0, 'forecast_window_days': 5, 'stp_overflow_penalty_kg_co2_per_ton': 1000.0}\n",
      "\n",
      "STP REGISTRY (4 records)\n",
      "  stp_id  latitude  longitude  storage_max_tons  daily_output_tons\n",
      "0  STP-1    9.9312    76.2673               100                 15\n",
      "1  STP-2    8.5241    76.9366               120                 18\n",
      "2  STP-3   11.2588    75.7804                80                 12\n",
      "3  STP-4   10.5276    76.2144                90                 14\n",
      "\n",
      "FARM LOCATIONS ({len(farms)} records)\n",
      "   farm_id   latitude  longitude weather_zone\n",
      "0        1  12.321321  77.129820        South\n",
      "1        2   8.639365  75.592946      Central\n",
      "2        3  11.550570  74.964253      Central\n",
      "3        4  12.037436  77.074362        South\n",
      "4        5  11.541312  75.655421        South\n",
      "\n",
      "VALIDATION COMPLETE\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 22:58:31,505 - INFO - \n",
      "============================================================\n",
      "2026-01-14 22:58:31,506 - INFO - RUNNING 3-DAY SIMULATION\n",
      "2026-01-14 22:58:31,507 - INFO - ============================================================\n",
      "\n",
      "2026-01-14 22:58:31,604 - INFO -   Score: 19286.02 | Deliveries:  16 | Efficiency:  0.001\n",
      "2026-01-14 22:58:31,644 - INFO -   Score: 38760.15 | Deliveries:  17 | Efficiency:  0.000\n",
      "2026-01-14 22:58:31,687 - INFO -   Score: 58307.85 | Deliveries:  16 | Efficiency:  0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2ï¸âƒ£ SIMULATION\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ“… Day 1: 2025-01-01\n",
      "\n",
      "ðŸ“… Day 2: 2025-01-02\n",
      "\n",
      "ðŸ“… Day 3: 2025-01-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 22:58:31,690 - INFO - \n",
      "============================================================\n",
      "2026-01-14 22:58:31,690 - INFO - SIMULATION COMPLETE\n",
      "2026-01-14 22:58:31,691 - INFO - ============================================================\n",
      "2026-01-14 22:58:31,692 - INFO - Total CO2eq Score: 116354.01\n",
      "2026-01-14 22:58:31,693 - INFO - Total Deliveries: 49\n",
      "2026-01-14 22:58:31,696 - INFO - Average per day: 16.3\n",
      "2026-01-14 22:58:31,697 - INFO - ============================================================\n",
      "\n",
      "2026-01-14 22:58:31,703 - INFO - Solution CSV shape: (49, 4)\n",
      "2026-01-14 22:58:31,704 - INFO - \n",
      "First 5 rows:\n",
      "2026-01-14 22:58:31,713 - INFO - \n",
      "ðŸ’¾ Saved to: output\\solution_20260114_225831.csv\n",
      "2026-01-14 22:58:31,719 - INFO - ðŸ’¾ Also saved as: output\\solution.csv\n",
      "2026-01-14 22:58:31,721 - ERROR - Failed to generate summary metrics: argument of type 'numpy.float64' is not iterable\n",
      "2026-01-14 22:58:31,722 - INFO - \n",
      "Validating results...\n",
      "2026-01-14 22:58:31,725 - INFO - âœ“ All validations passed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3ï¸âƒ£ OUTPUT GENERATION\n",
      "----------------------------------------\n",
      "         date stp_id  farm_id  tons_delivered\n",
      "0  2025-01-01  STP-1       15           5.049\n",
      "1  2025-01-01  STP-1        9           6.517\n",
      "2  2025-01-01  STP-1       12           3.434\n",
      "3  2025-01-01  STP-2       19           5.898\n",
      "4  2025-01-01  STP-2        2           4.096\n",
      "\n",
      "4ï¸âƒ£ METRICS GENERATION\n",
      "----------------------------------------\n",
      "\n",
      "5ï¸âƒ£ VALIDATION\n",
      "----------------------------------------\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ‰ TEST COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ GENERATED FILES:\n",
      "  - solution.csv (1313 bytes)\n",
      "  - solution_20260114_225831.csv (1313 bytes)\n",
      "  - solution_step8_test.csv (356 bytes)\n",
      "\n",
      "âœ… READY FOR NEXT STEPS:\n",
      "   1. Run 7-day full simulation\n",
      "   2. Connect dashboard to real data\n",
      "   3. Implement Triple-Lens algorithm\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prasanna rajan R\\Documents\\GitHub\\kerala-biosolids-hackathon\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3709: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# Fix paths - Run from project root\n",
    "# -----------------------------\n",
    "project_root = Path.cwd()\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Ensure we're in the right directory\n",
    "if not (project_root / 'data').exists():\n",
    "    print(\"WARNING: 'data' folder not found in current directory\")\n",
    "    print(\"Switching to parent directory...\")\n",
    "    project_root = project_root.parent\n",
    "    os.chdir(project_root)\n",
    "    print(f\"New working directory: {os.getcwd()}\")\n",
    "\n",
    "sys.path.append(str(project_root))\n",
    "sys.path.append(str(project_root / 'src'))\n",
    "\n",
    "print(f\"Project root added to sys.path: {project_root}\")\n",
    "print(f\"Python path: {sys.path}\")\n",
    "# -----------------------------\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class BaselineAlgorithmTester:\n",
    "    \"\"\"Comprehensive testing framework for baseline algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir=\"data\", num_farms=250, num_days=7):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.num_farms = num_farms\n",
    "        self.num_days = num_days\n",
    "        self.metrics = {\n",
    "            'daily_scores': [],\n",
    "            'daily_deliveries': [],\n",
    "            'daily_efficiency': [],\n",
    "            'timestamps': []\n",
    "        }\n",
    "        self.algorithm = None\n",
    "        \n",
    "        # Create data directory if it doesn't exist\n",
    "        self.data_dir.mkdir(exist_ok=True)\n",
    "        print(f\"Data directory: {self.data_dir.absolute()}\")\n",
    "    \n",
    "    def setup(self):\n",
    "        \"\"\"Initialize data and algorithm.\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Loading data...\")\n",
    "            \n",
    "            # First, check what files we have\n",
    "            print(\"\\nChecking data files...\")\n",
    "            required_files = [\n",
    "                'parameters.json',\n",
    "                'stp_registry.csv', \n",
    "                'farm_locations.csv',\n",
    "                'daily_n_demand.csv',\n",
    "                'weather_forecast.csv'\n",
    "            ]\n",
    "            \n",
    "            missing_files = []\n",
    "            for file in required_files:\n",
    "                file_path = self.data_dir / file\n",
    "                if file_path.exists():\n",
    "                    print(f\"âœ“ Found: {file}\")\n",
    "                else:\n",
    "                    print(f\"âœ— Missing: {file}\")\n",
    "                    missing_files.append(file)\n",
    "            \n",
    "            # If we're missing data, create it\n",
    "            if missing_files:\n",
    "                logger.info(f\"Creating {len(missing_files)} missing data files...\")\n",
    "                self.create_missing_data(missing_files)\n",
    "            \n",
    "            # Now load the data\n",
    "            from src.utils.data_loader import DataLoader\n",
    "            loader = DataLoader(data_path=str(self.data_dir))\n",
    "            params, stps_df, farms_df = loader.validate_data()\n",
    "            \n",
    "            logger.info(f\"Loaded {len(stps_df)} STPs and {len(farms_df)} farms\")\n",
    "            \n",
    "            # Load demand and weather data\n",
    "            try:\n",
    "                self.demand_df = pd.read_csv(self.data_dir / 'daily_n_demand.csv')\n",
    "                self.weather_df = pd.read_csv(self.data_dir / 'weather_forecast.csv')\n",
    "                logger.info(f\"Loaded demand data: {len(self.demand_df)} records\")\n",
    "                logger.info(f\"Loaded weather data: {len(self.weather_df)} records\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to load data files: {e}\")\n",
    "                # Generate synthetic data\n",
    "                from src.utils.data_simulator import DataSimulator\n",
    "                simulator = DataSimulator(data_path=str(self.data_dir), num_farms=self.num_farms)\n",
    "                self.demand_df = simulator.generate_daily_demand(num_days=self.num_days)\n",
    "                self.weather_df = simulator.generate_weather_forecast()\n",
    "            \n",
    "            logger.info(\"Initializing algorithm...\")\n",
    "            from src.algorithm.greedy_baseline import GreedyBaseline\n",
    "            self.algorithm = GreedyBaseline(params, stps_df, farms_df)\n",
    "            self.params = params\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Setup failed: {e}\", exc_info=True)\n",
    "            return False\n",
    "    \n",
    "    def create_missing_data(self, missing_files):\n",
    "        \"\"\"Create missing data files.\"\"\"\n",
    "        import json\n",
    "        \n",
    "        # Create parameters.json if missing\n",
    "        if 'parameters.json' in missing_files:\n",
    "            params = {\n",
    "                'transport_emission_factor': 0.9,\n",
    "                'fertilizer_offset_factor': 5.0,\n",
    "                'soil_sequestration_factor': 0.2,\n",
    "                'excess_n_penalty': 10.0,\n",
    "                'overflow_penalty_per_ton': 1000\n",
    "            }\n",
    "            with open(self.data_dir / 'parameters.json', 'w') as f:\n",
    "                json.dump(params, f, indent=2)\n",
    "            print(\"Created parameters.json\")\n",
    "        \n",
    "        # Create STP data if missing\n",
    "        if 'stp_registry.csv' in missing_files:\n",
    "            stp_data = {\n",
    "                'stp_id': ['STP-1', 'STP-2', 'STP-3', 'STP-4'],\n",
    "                'latitude': [9.9312, 8.5241, 11.2588, 10.5276],\n",
    "                'longitude': [76.2673, 76.9366, 75.7804, 76.2144],\n",
    "                'storage_max_tons': [100, 120, 80, 90],\n",
    "                'daily_output_tons': [15, 18, 12, 14]\n",
    "            }\n",
    "            pd.DataFrame(stp_data).to_csv(self.data_dir / 'stp_registry.csv', index=False)\n",
    "            print(\"Created stp_registry.csv\")\n",
    "        \n",
    "        # Create farm data if missing (use 20 farms for testing)\n",
    "        if 'farm_locations.csv' in missing_files:\n",
    "            farm_ids = list(range(1, 21))\n",
    "            farm_data = {\n",
    "                'farm_id': farm_ids,\n",
    "                'latitude': [8.5 + np.random.random() * 4.5 for _ in farm_ids],\n",
    "                'longitude': [74.5 + np.random.random() * 3.0 for _ in farm_ids],\n",
    "                'weather_zone': np.random.choice(['North', 'Central', 'South'], size=len(farm_ids))\n",
    "            }\n",
    "            pd.DataFrame(farm_data).to_csv(self.data_dir / 'farm_locations.csv', index=False)\n",
    "            print(\"Created farm_locations.csv (20 farms)\")\n",
    "    \n",
    "    def run_simulation(self):\n",
    "        \"\"\"Run the simulation for all days.\"\"\"\n",
    "        if not self.algorithm:\n",
    "            logger.error(\"Algorithm not initialized. Call setup() first.\")\n",
    "            return False\n",
    "        \n",
    "        logger.info(\"\\n\" + \"=\"*60)\n",
    "        logger.info(f\"RUNNING {self.num_days}-DAY SIMULATION\")\n",
    "        logger.info(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        # Get unique dates\n",
    "        dates = sorted(self.demand_df['date'].unique())[:self.num_days]\n",
    "        \n",
    "        total_score = 0\n",
    "        total_deliveries = 0\n",
    "        \n",
    "        for i, date in enumerate(dates, 1):\n",
    "            try:\n",
    "                print(f\"\\nðŸ“… Day {i}: {date}\")\n",
    "                daily_score = self.algorithm.run_day(date, self.demand_df, self.weather_df)\n",
    "                \n",
    "                # Count deliveries for this day\n",
    "                day_deliveries = [d for d in self.algorithm.deliveries if d.get('date') == date]\n",
    "                num_deliveries = len(day_deliveries)\n",
    "                \n",
    "                # Calculate efficiency (deliveries per unit score)\n",
    "                efficiency = num_deliveries / (abs(daily_score) + 1e-6) if daily_score != 0 else 0\n",
    "                \n",
    "                total_score += daily_score\n",
    "                total_deliveries += num_deliveries\n",
    "                \n",
    "                # Store metrics\n",
    "                self.metrics['daily_scores'].append(daily_score)\n",
    "                self.metrics['daily_deliveries'].append(num_deliveries)\n",
    "                self.metrics['daily_efficiency'].append(efficiency)\n",
    "                self.metrics['timestamps'].append(date)\n",
    "                \n",
    "                logger.info(f\"  Score: {daily_score:>8.2f} | \"\n",
    "                           f\"Deliveries: {num_deliveries:>3} | \"\n",
    "                           f\"Efficiency: {efficiency:>6.3f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error on day {i} ({date}): {e}\", exc_info=True)\n",
    "                return False\n",
    "        \n",
    "        logger.info(\"\\n\" + \"=\"*60)\n",
    "        logger.info(\"SIMULATION COMPLETE\")\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(f\"Total CO2eq Score: {total_score:.2f}\")\n",
    "        logger.info(f\"Total Deliveries: {total_deliveries}\")\n",
    "        logger.info(f\"Average per day: {total_deliveries/self.num_days:.1f}\")\n",
    "        logger.info(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        self.total_score = total_score\n",
    "        self.total_deliveries = total_deliveries\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def get_solution_csv(self, save=True):\n",
    "        \"\"\"Retrieve and display solution data.\"\"\"\n",
    "        try:\n",
    "            solution_df = self.algorithm.get_solution_csv()\n",
    "            \n",
    "            if solution_df.empty:\n",
    "                logger.warning(\"No deliveries recorded in solution.csv\")\n",
    "                return None\n",
    "            \n",
    "            logger.info(f\"Solution CSV shape: {solution_df.shape}\")\n",
    "            logger.info(f\"\\nFirst 5 rows:\")\n",
    "            print(solution_df.head().to_string())\n",
    "            \n",
    "            if save:\n",
    "                # Create output directory\n",
    "                output_dir = Path('output')\n",
    "                output_dir.mkdir(exist_ok=True)\n",
    "                \n",
    "                # Save solution\n",
    "                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                output_path = output_dir / f'solution_{timestamp}.csv'\n",
    "                solution_df.to_csv(output_path, index=False)\n",
    "                logger.info(f\"\\nðŸ’¾ Saved to: {output_path}\")\n",
    "                \n",
    "                # Also save as the main solution.csv\n",
    "                main_path = output_dir / 'solution.csv'\n",
    "                solution_df.to_csv(main_path, index=False)\n",
    "                logger.info(f\"ðŸ’¾ Also saved as: {main_path}\")\n",
    "            \n",
    "            return solution_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to get solution CSV: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_summary_metrics(self):\n",
    "        \"\"\"Generate summary_metrics.json in required format.\"\"\"\n",
    "        try:\n",
    "            # Calculate metrics\n",
    "            total_tons = sum(d.get('tons_delivered', 0) for d in self.algorithm.deliveries)\n",
    "            \n",
    "            # Carbon breakdown (simplified)\n",
    "            carbon_breakdown = {\n",
    "                'fertilizer_offset': 0,\n",
    "                'soil_sequestration': 0,\n",
    "                'transport_cost': 0,\n",
    "                'excess_penalty': 0,\n",
    "                'overflow_penalty': 0\n",
    "            }\n",
    "            \n",
    "            for delivery in self.algorithm.deliveries:\n",
    "                if 'carbon_impact' in delivery:\n",
    "                    impact = delivery['carbon_impact']\n",
    "                    for key in carbon_breakdown:\n",
    "                        if key in impact:\n",
    "                            carbon_breakdown[key] += impact[key]\n",
    "            \n",
    "            summary = {\n",
    "                \"total_carbon_credits_kg\": round(self.total_score, 2),\n",
    "                \"total_deliveries\": self.total_deliveries,\n",
    "                \"total_tons_delivered\": round(total_tons, 2),\n",
    "                \"average_tons_per_delivery\": round(total_tons / self.total_deliveries, 3) if self.total_deliveries > 0 else 0,\n",
    "                \"simulation_days\": self.num_days,\n",
    "                \"average_daily_carbon\": round(self.total_score / self.num_days, 2),\n",
    "                \"carbon_breakdown\": {k: round(v, 2) for k, v in carbon_breakdown.items()}\n",
    "            }\n",
    "            \n",
    "            # Save to JSON\n",
    "            output_dir = Path('output')\n",
    "            output_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            summary_path = output_dir / 'summary_metrics.json'\n",
    "            with open(summary_path, 'w') as f:\n",
    "                json.dump(summary, f, indent=2)\n",
    "            \n",
    "            logger.info(f\"ðŸ“Š Summary metrics saved to: {summary_path}\")\n",
    "            logger.info(\"\\nSummary:\")\n",
    "            for key, value in summary.items():\n",
    "                if key != 'carbon_breakdown':\n",
    "                    logger.info(f\"  {key}: {value}\")\n",
    "            \n",
    "            return summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to generate summary metrics: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def validate_results(self):\n",
    "        \"\"\"Validate simulation results for consistency.\"\"\"\n",
    "        logger.info(\"\\nValidating results...\")\n",
    "        \n",
    "        issues = []\n",
    "        \n",
    "        # Check solution.csv format\n",
    "        solution_df = self.algorithm.get_solution_csv()\n",
    "        if not solution_df.empty:\n",
    "            required_columns = ['date', 'stp_id', 'farm_id', 'tons_delivered']\n",
    "            missing_columns = [col for col in required_columns if col not in solution_df.columns]\n",
    "            \n",
    "            if missing_columns:\n",
    "                issues.append(f\"Missing columns in solution: {missing_columns}\")\n",
    "            \n",
    "            # Check for negative tons\n",
    "            if (solution_df['tons_delivered'] < 0).any():\n",
    "                issues.append(\"Negative tons_delivered values found\")\n",
    "            \n",
    "            # Check for reasonable values\n",
    "            max_tons = solution_df['tons_delivered'].max()\n",
    "            if max_tons > 10:  # Truck capacity\n",
    "                issues.append(f\"Delivery exceeds truck capacity: {max_tons} tons\")\n",
    "        \n",
    "        # Check carbon score sign (should be positive)\n",
    "        if self.total_score < 0:\n",
    "            issues.append(f\"Total carbon score is negative: {self.total_score}\")\n",
    "        \n",
    "        if issues:\n",
    "            logger.warning(f\"Found {len(issues)} issues:\")\n",
    "            for issue in issues:\n",
    "                logger.warning(f\"  - {issue}\")\n",
    "            return False\n",
    "        else:\n",
    "            logger.info(\"âœ“ All validations passed\")\n",
    "            return True\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 8: COMPREHENSIVE ALGORITHM TEST\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        # Initialize tester\n",
    "        tester = BaselineAlgorithmTester(data_dir=\"data\", num_farms=20, num_days=3)\n",
    "        \n",
    "        print(\"\\n1ï¸âƒ£ SETUP\")\n",
    "        print(\"-\"*40)\n",
    "        if not tester.setup():\n",
    "            logger.error(\"Setup failed. Exiting.\")\n",
    "            return 1\n",
    "        \n",
    "        print(\"\\n2ï¸âƒ£ SIMULATION\")\n",
    "        print(\"-\"*40)\n",
    "        if not tester.run_simulation():\n",
    "            logger.error(\"Simulation failed. Exiting.\")\n",
    "            return 1\n",
    "        \n",
    "        print(\"\\n3ï¸âƒ£ OUTPUT GENERATION\")\n",
    "        print(\"-\"*40)\n",
    "        solution_df = tester.get_solution_csv(save=True)\n",
    "        \n",
    "        print(\"\\n4ï¸âƒ£ METRICS GENERATION\")\n",
    "        print(\"-\"*40)\n",
    "        tester.generate_summary_metrics()\n",
    "        \n",
    "        print(\"\\n5ï¸âƒ£ VALIDATION\")\n",
    "        print(\"-\"*40)\n",
    "        tester.validate_results()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ðŸŽ‰ TEST COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(\"\\nðŸ“ GENERATED FILES:\")\n",
    "        output_dir = Path('output')\n",
    "        if output_dir.exists():\n",
    "            for file in output_dir.iterdir():\n",
    "                print(f\"  - {file.name} ({file.stat().st_size} bytes)\")\n",
    "        \n",
    "        print(\"\\nâœ… READY FOR NEXT STEPS:\")\n",
    "        print(\"   1. Run 7-day full simulation\")\n",
    "        print(\"   2. Connect dashboard to real data\")\n",
    "        print(\"   3. Implement Triple-Lens algorithm\")\n",
    "        \n",
    "        return 0\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        logger.info(\"Test interrupted by user\")\n",
    "        return 1\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error: {e}\", exc_info=True)\n",
    "        return 1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    exit_code = main()\n",
    "    sys.exit(exit_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
